# PromoBG ğŸ›’

> Bulgarian grocery price comparison - Find the best deals across supermarkets

**Live Demo:** https://martinpetrov8.github.io/promo_products_bg/

---

## ğŸ¯ What is PromoBG?

PromoBG aggregates promotional offers from major Bulgarian supermarkets, allowing users to:
- **Compare prices** across Kaufland, Lidl, and Billa
- **Find the best deals** with discount filtering
- **Search products** in Bulgarian
- **Save money** by knowing where to shop

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PromoBG System                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Kaufland    â”‚    â”‚    Lidl      â”‚    â”‚    Billa     â”‚      â”‚
â”‚  â”‚   Scraper    â”‚    â”‚   Scraper    â”‚    â”‚   Scraper    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                   â”‚                   â”‚               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                             â”‚                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                    â”‚ Combined Scraper â”‚                         â”‚
â”‚                    â”‚ (merged data)    â”‚                         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                             â”‚                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                    â”‚ all_products.jsonâ”‚                         â”‚
â”‚                    â”‚  (1,537 items)   â”‚                         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                             â”‚                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                    â”‚   Web Frontend   â”‚                         â”‚
â”‚                    â”‚  (Static HTML)   â”‚                         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
promo_products_bg/
â”œâ”€â”€ docs/                    # GitHub Pages deployment
â”‚   â”œâ”€â”€ index.html          # Live MVP
â”‚   â””â”€â”€ data/               # Product JSON
â”‚
â”œâ”€â”€ apps/
â”‚   â””â”€â”€ web/                # Web application source
â”‚       â”œâ”€â”€ index.html
â”‚       â””â”€â”€ data/
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”œâ”€â”€ scrapers/       # Individual store scrapers
â”‚   â”‚   â”‚   â”œâ”€â”€ kaufland_scraper.py
â”‚   â”‚   â”‚   â”œâ”€â”€ lidl_scraper.py
â”‚   â”‚   â”‚   â””â”€â”€ billa_scraper.py
â”‚   â”‚   â”œâ”€â”€ combined_scraper.py
â”‚   â”‚   â””â”€â”€ data/           # Scraped data
â”‚   â”‚
â”‚   â””â”€â”€ api/                # FastAPI backend (future)
â”‚       â””â”€â”€ main.py
â”‚
â”œâ”€â”€ research/               # Market research & UI patterns
â”‚   â””â”€â”€ competitor-ui-patterns.md
â”‚
â”œâ”€â”€ PLAN.md                 # Detailed project plan
â””â”€â”€ README.md               # This file
```

---

## ğŸ”„ Data Flow

### Step 1: Scraping
```
Kaufland.bg â”€â”€â†’ kaufland_scraper.py â”€â”€â†’ kaufland_products.json
Lidl.bg     â”€â”€â†’ lidl_scraper.py     â”€â”€â†’ lidl_products.json
ssbbilla.site â”€â†’ billa_scraper.py   â”€â”€â†’ billa_products.json
```

### Step 2: Combining
```
All JSON files â”€â”€â†’ combined_scraper.py â”€â”€â†’ all_products.json
```

### Step 3: Serving
```
all_products.json â”€â”€â†’ index.html (loads via fetch) â”€â”€â†’ User sees deals
```

---

## ğŸš€ Quick Start

### Run Scrapers
```bash
cd services/scraper
python3 combined_scraper.py
```

### View Locally
```bash
cd apps/web
python3 -m http.server 3001
# Open http://localhost:3001
```

### Deploy to GitHub Pages
```bash
# Copy web files to docs/
cp -r apps/web/* docs/

# Commit and push
git add docs/
git commit -m "Update deployment"
git push

# Enable GitHub Pages in repo settings:
# Settings â†’ Pages â†’ Source: Deploy from branch â†’ main â†’ /docs
```

---

## ğŸ“Š Data Schema

Each product follows this schema:

```json
{
  "id": "abc123def456",
  "name": "ĞÑƒÑ‚ĞµĞ»Ğ° 400Ğ³",
  "store": "Kaufland",
  "price_eur": 3.49,
  "price_bgn": 6.83,
  "old_price_eur": 4.99,
  "old_price_bgn": 9.76,
  "discount_pct": 30,
  "quantity": "400 Ğ³",
  "category": "Ğ¡Ğ»Ğ°Ğ´ĞºĞ¾",
  "image_url": "https://...",
  "scraped_at": "2026-02-12T05:30:00Z"
}
```

---

## ğŸ› ï¸ Development Workflow

### Adding a New Store

1. **Create scraper** in `services/scraper/scrapers/`
   ```python
   # newstore_scraper.py
   def scrape_newstore() -> List[Product]:
       # Fetch and parse store website
       # Return list of Product objects
   ```

2. **Add to combined scraper**
   ```python
   # In combined_scraper.py
   from scrapers.newstore_scraper import scrape_newstore
   
   def scrape_all():
       # ... existing code ...
       all_products.extend(scrape_newstore())
   ```

3. **Run and verify**
   ```bash
   python3 combined_scraper.py
   ```

4. **Update deployment**
   ```bash
   cp services/scraper/data/all_products.json docs/data/
   git add . && git commit -m "Add NewStore" && git push
   ```

### Updating UI

1. Edit `apps/web/index.html`
2. Test locally: `python3 -m http.server 3001`
3. Copy to docs: `cp apps/web/index.html docs/`
4. Commit and push

---

## ğŸ“ˆ Roadmap

### Phase 1: MVP âœ…
- [x] Kaufland scraper
- [x] Lidl scraper
- [x] Billa scraper
- [x] Combined data pipeline
- [x] Basic search UI
- [x] Store/discount filters
- [x] GitHub Pages deployment

### Phase 2: Enhanced Comparison
- [ ] Side-by-side price comparison
- [ ] "Best price" winner highlighting
- [ ] Price per kg/L normalization
- [ ] Price history tracking

### Phase 3: Engagement
- [ ] Price alerts (email/Viber)
- [ ] Watchlist/favorites
- [ ] User accounts
- [ ] Mobile app

### Phase 4: Monetization
- [ ] Google AdSense
- [ ] Affiliate links (eMAG, etc.)
- [ ] Sponsored placements

---

## ğŸ‘¥ Team

- **Martin** - Project lead
- **Maria** - Business development
- **Cookie ğŸª** - AI development assistant

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE)

---

## ğŸ”— Links

- **Live Demo:** https://martinpetrov8.github.io/promo_products_bg/
- **Project Plan:** [PLAN.md](PLAN.md)
- **UI Research:** [research/competitor-ui-patterns.md](research/competitor-ui-patterns.md)
